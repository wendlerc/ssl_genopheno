{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import sys\n",
    "sys.path.append('../project/genotype')\n",
    "from data import GenotypeDataModule\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pattern = \"../datasets/genotype/cas9/cas9_pairs_10nm_%s.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = \"GACGCATAAAGATGAGACGCTGG\"\n",
    "pair2int = {pair: idx for  idx, pair in enumerate(product(['A', 'C', 'G', 'T'], ['A', 'C', 'G', 'T']))}\n",
    "int2pair = {idx: pair for idx, pair in enumerate(product(['A', 'C', 'G', 'T'], ['A', 'C', 'G', 'T']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = path_pattern \n",
    "dm = GenotypeDataModule(paths = [pp%\"train\", pp%\"valid\", pp%\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dm.X_train.numpy()\n",
    "X_valid = dm.X_valid.numpy()\n",
    "X_test = dm.X_test.numpy()\n",
    "Y_train = dm.y_train.numpy()[:, 0]\n",
    "Y_valid = dm.y_valid.numpy()[:, 0]\n",
    "Y_test  = dm.y_test.numpy()[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base2int = {'A': 1, 'C': 2, 'G': 3, 'T':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(X):\n",
    "    mask0 = (X == pair2int[('A', 'A')]) + (X == pair2int[('C', 'C')]) + (X == pair2int[('G', 'G')]) + (X == pair2int[('T', 'T')])\n",
    "    binary = X.copy()\n",
    "    binary[mask0] = 0\n",
    "    binary[~mask0] = 1\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_string(X):\n",
    "    string = []\n",
    "    for row in X:\n",
    "        string += [[base2int[int2pair[x][1]] for x in row]]\n",
    "    return np.asarray(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_hamming(X):\n",
    "    mask0 = (X == pair2int[('A', 'A')]) + (X == pair2int[('C', 'C')]) + (X == pair2int[('G', 'G')]) + (X == pair2int[('T', 'T')])\n",
    "    hamming = []\n",
    "    for row in X:\n",
    "        hamming += [[base2int[int2pair[x][1]] for x in row]]\n",
    "    hamming = np.asarray(hamming)\n",
    "    hamming[mask0] = 0\n",
    "    return hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_string, X_valid_string, X_test_string = to_string(X_train), to_string(X_valid), to_string(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n",
    "              'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [25,50,65,80,100,115,130,150,200,400,800],\n",
    "              'reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "              'reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'reg_lambda': 200, 'reg_alpha': 0, 'n_estimators': 400, 'max_depth': 14, 'learning_rate': 0.4, 'gamma': 0.2, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "X_train_valid_string = np.concatenate((X_train_string, X_valid_string), axis=0)\n",
    "cv = RandomizedSearchCV(xgb.XGBRegressor(), param_grid, n_iter=1000, cv=ps)\n",
    "cv.fit(X_train_valid_string, Y_train_valid)\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN  R2 score: 0.6220, relative error: 0.6147\n",
      "TEST   R2 score: 0.4033, relative error: 0.7700\n"
     ]
    }
   ],
   "source": [
    "#est = xgb.XGBRegressor(**cv.best_params_)\n",
    "est = xgb.XGBRegressor(**{'subsample': 0.8, 'reg_lambda': 200, 'reg_alpha': 0, 'n_estimators': 400, 'max_depth': 14, 'learning_rate': 0.4, 'gamma': 0.2, 'colsample_bytree': 0.6})\n",
    "est.fit(X_train_string, Y_train)\n",
    "Y_pred = est.predict(X_test_string)\n",
    "Y_pred2 = est.predict(X_train_string)\n",
    "r2_train = r2_score(Y_train, Y_pred2)\n",
    "rel_train = np.linalg.norm(Y_train - Y_pred2)/np.linalg.norm(Y_train)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "rel = np.linalg.norm(Y_test - Y_pred)/np.linalg.norm(Y_test)\n",
    "print('TRAIN  R2 score: %2.4f, relative error: %2.4f'%(r2_train, rel_train))\n",
    "print('TEST   R2 score: %2.4f, relative error: %2.4f'%(r2, rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'subsample': 0.8, 'reg_lambda': 200, 'reg_alpha': 0, 'n_estimators': 400, 'max_depth': 14, 'learning_rate': 0.4, 'gamma': 0.2, 'colsample_bytree': 0.6}\n",
    "# TRAIN  R2 score: 0.6220, relative error: 0.6147\n",
    "# TEST   R2 score: 0.4033, relative error: 0.7700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hamming, X_valid_hamming, X_test_hamming = to_hamming(X_train), to_hamming(X_valid), to_hamming(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'reg_lambda': 12.8, 'reg_alpha': 0.2, 'n_estimators': 400, 'max_depth': 14, 'learning_rate': 0.300000012, 'gamma': 1.6, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "X_train_valid_hamming = np.concatenate((X_train_hamming, X_valid_hamming), axis=0)\n",
    "cv = RandomizedSearchCV(xgb.XGBRegressor(), param_grid, n_iter=1000, cv=ps)\n",
    "cv.fit(X_train_valid_hamming, Y_train_valid)\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN  R2 score: 0.7139, relative error: 0.5348\n",
      "TEST   R2 score: 0.5050, relative error: 0.7013\n"
     ]
    }
   ],
   "source": [
    "est = xgb.XGBRegressor(**cv.best_params_)\n",
    "est.fit(X_train_hamming, Y_train)\n",
    "Y_pred = est.predict(X_test_hamming)\n",
    "Y_pred2 = est.predict(X_train_hamming)\n",
    "r2_train = r2_score(Y_train, Y_pred2)\n",
    "rel_train = np.linalg.norm(Y_train - Y_pred2)/np.linalg.norm(Y_train)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "rel = np.linalg.norm(Y_test - Y_pred)/np.linalg.norm(Y_test)\n",
    "print('TRAIN  R2 score: %2.4f, relative error: %2.4f'%(r2_train, rel_train))\n",
    "print('TEST   R2 score: %2.4f, relative error: %2.4f'%(r2, rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamming\n",
    "# {'subsample': 0.8, 'reg_lambda': 12.8, 'reg_alpha': 0.2, 'n_estimators': 400, 'max_depth': 14, 'learning_rate': 0.300000012, 'gamma': 1.6, 'colsample_bytree': 1.0}\n",
    "# TRAIN  R2 score: 0.7139, relative error: 0.5348\n",
    "# TEST   R2 score: 0.5050, relative error: 0.7013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
